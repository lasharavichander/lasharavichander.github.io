<!DOCTYPE html>
<html lang="en">

<head>
   <meta charset="utf-8">
   <meta http-equiv="X-UA-Compatible" content="IE=edge">
   <meta name="viewport" content="width=device-width, initial-scale=1">
   <meta name="description" content="">
   <meta name="author" content="Abhilasha Ravichander">
   <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
   <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
   <script src="https://kit.fontawesome.com/08daa0274c.js" crossorigin="anonymous"></script>
   <script src="http://platform.twitter.com/widgets.js" type="text/javascript"></script>
   <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
      integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
   <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"></script>
   <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQRavichander7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"></script>
   <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"></script>
   <link href="tools/bootstrap/css/heroic-features.css" rel="stylesheet">
   <title>Abhilasha Ravichander - Home</title>
</head>

<body>
   <script async src="https://www.googletagmanager.com/gtag/js?id=UA-82392196-1"></script>
   <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());

      gtag('config', 'UA-82392196-1');
   </script>
   <style>
      .label-dataset {
         background-color: #9b59b6;
      }

      .label-dataset[href]:hover,
      .label-dataset[href]:focus {
         background-color: #8e44ad;
      }

      .label-video {
         background-color: #ffcccc;
      }

      .label-best {
         background-color: #99004d;
      }

      .label-short {
         background-color: #d27979;
      }

      .label-long {
         background-color: #26004d;
      }


      .label-pdf {
         background-color: #643191;
         color: white;
         padding: 2px;
         margin-left: 1px;
         margin-right: 1px;
      }

      .label-code {
         background-color: #4350c6;
         color: white;
         padding: 2px;
         margin-left: 1px;
         margin-right: 1px;
      }

      .label-slides {
         background-color: #317d91;
         color: white;
         padding: 2px;
         margin-left: 1px;
         margin-right: 1px;
      }

      .label-website {
         background-color: #99004d;
         color: white;
         padding: 2px;
         margin-left: 1px;
         margin-right: 1px;
      }

      .label-short {
         background-color: #076b3e;
         color: white;
         padding: 2px;
         margin-left: 1px;
         margin-right: 1px;
      }

      .label-long {
         background-color: #379138;
         color: white;
         padding: 2px;
         margin-left: 1px;
         margin-right: 1px;
      }
   </style>



   <style type="text/css">
      #research {
         active: true;
      }
   </style>
   <style>
      #menu {
         display: table;
         width: 100%;
         background: #ffeeee;
         margin-bottom: 30px;
         /*  border-bottom: 1px solid #999;*/
      }

      .label-striped {
         background-color: #e6ecf0;
         padding: 2px;
         margin-left: 0px;
         margin-right: 1px;
      }

      #menu div {
         display: table-cell;
         width: 20%;
         text-align: center;
         vertical-align: middle;
         font-weight: 500;
         color: #333;
      }

      #menu div:hover {
         background: #5f699c;
      }

      #menu .now {
         background: #5f699c;
         color: crimson;
      }

      #menu a {
         display: block;
         padding: 5px 0 5px 0;
         color: inherit;
      }

      #menu a:hover {
         text-decoration: none;
      }
   </style>
   <script>
      // When the user scrolls the page, execute myFunction
      window.onscroll = function () { myFunction() };

      // Get the navbar
      var navbar = document.getElementById("navbar");

      // Get the offset position of the navbar
      var sticky = navbar.offsetTop;

      // Add the sticky class to the navbar when you reach its scroll position. Remove "sticky" when you leave the scroll position
      function myFunction() {
         if (window.pageYOffset >= sticky) {
            navbar.classList.add("sticky")
         } else {
            navbar.classList.remove("sticky");
         }
      }
   </script>
   <!-- Page Content -->
   <!--div class="clearfix hidden-sm-up"></div-->

   <div class="row" id="navbar">
      <div id="menu"
         style="background-color:#30429c;border:1px solid #ccc; font-size:16px;position:fixed;z-index: 1100;">
         <div>
            <a href="#" style="color:#FFFFFF">Home</a>
         </div>
         <div>
            <a href="#news" style="color:#FFFFFF">News</a>
         </div>
         <div>
            <a href="#publications" style="color:#FFFFFF">Publications</a>
         </div>
         <!--               <div>-->
         <!--                  <a href="#service" style="color:#FFFFFF">Service</a>-->
         <!--               </div>-->
         <!--               <div>-->
         <!--                  <a href="#contact" style="color:#FFFFFF">Contact</a>-->
         <!--               </div>-->

         <script>
            $(function () {
               const current = window.location.pathname.split("/");
               $('#menu div a').each(function () {
                  const $this = $(this);
                  // if the current path is like this link, make it active
                  if (current.indexOf($this.attr("href")) !== -1) {
                     $this.parent().addClass("now");
                  }
               })
            });
         </script>
      </div>
   </div>

   <div class="container" style="padding-top: 10px;max-width: 80%; ">
      <div class="row justify-content-center">
         <div class="col-sm-12 col-md-12 col-lg-10">
            </br></br>
            <!-- Jumbotron Header -->
            <!--div class="jumbotron" style="display: inline-block">
               <img src="files/M6.jpg" alt="Abhilasha Ravichander" style="padding-left:10px; margin-right: 15px; max-width:135px;float:left">
               <p id="intro-text">Hi! I'm Abhilasha Ravichander, currently a PhD student at the University of Washington.
               I'm interested in natural language processing, specifically contextual language modelling and social science NLP applications.
               </p>ebf1f5 image.jpg
               </div-->
            <!-- <div class="" style="padding: 2rem 1rem;background-color:#f0f0f5;"> -->
               <div class="" style="padding: 2rem 1rem;background-color:#ebebeb;">
               
               <div class="container row justify-content-center">
                  <div class="col-lg-3 col-md-3 col-sm-12">
                     <img class="profile" src="resources/ai2_pp.png" alt="Abhilasha Ravichander"
                        style="width: 100%; margin-bottom: 2em;">
                     <center>
                        <p> /ɑ.bʰi.ˈla.ʃə/</p>

                        <!-- 
                           <a class="twitter-follow-button" data-show-count="false"
                              href="https://twitter.com/Lasha1608"
                              data-size="large">
                           Twitter @Lasha1608</a> -->
                        <p>

                           <a href="mailto:aravicha@cs.washington.edu" target="_blank"><i class="fa fa-envelope"
                                 style="font-size:24px;color:black"></i></a>
                           <a href="https://twitter.com/lasha_nlp" target="_blank" style="font-size:24px;"><i
                                 class="fa fa-twitter"></i></a>
                           <a href="https://bsky.app/profile/lasha.bsky.social" target="_blank"><i class="fab fa-bluesky"
                                 style="font-size:24px;;color:black"></i></a>
                           <a href="https://www.linkedin.com/in/abhilasha-ravichander-57524958" target="_blank"
                              style="font-size:24px;"><i class="fa fa-linkedin"></i></a>
                           <a href="https://www.semanticscholar.org/author/Abhilasha-Ravichander/3023068"
                              target="_blank"><i class="ai ai-semantic-scholar-square ai-3x"
                                 style="font-size:24px;;color:black"></i></a>
                           <a href="https://scholar.google.com/citations?user=6vLsKGsAAAAJ" target="_blank"><i
                                 class="fa fa-google" style="font-size:24px;"></i></a>
                           <a href="https://github.com/AbhilashaRavichander" target="_blank"><i class="fa fa-github"
                                 style="font-size:24px;color:black"></i></a>

                           <a href="https://lasharavichander.github.io/Resume_Website.pdf" target="_blank"><i
                                 class="fa fa-book" style="font-size:24px;"></i></a>

                        </p>

                        <!--         <a href="https://twitter.com/intent/tweet?screen_name=Lasha1608&ref_src=twsrc%5Etfw" class="twitter-mention-button" data-show-count="false" data-size="large">Tweet to @Lasha1608</a> -->
                     </center>
                     <!--                 <a class="btn btn-light" href="http://twitter.com/Lasha1608" target="_blank">
                        <img src="files/twitter-icon.png" class="icon" title="Twitter Profile" alt="Twitter Profile">
                        </a>
                        <a class="btn btn-light" href="https://scholar.google.com/citations?user=gFN4QUYAAAAJ&hl=en" target="_blank">
                        <img src="files/google-scholar-icon.png" class="icon" title="Google Scholar Profile" alt="Google Scholar Profile">
                        </a>
                        <a class="btn btn-light" href="https://www.semanticscholar.org/author/Abhilasha-Ravichander/2729164" target="_blank">
                        <img src="files/s2-logo-bw.png" class="icon" title="Semantic Scholar Profile" alt="Semantic Scholar Profile">
                        </a> -->
                  </div>
                  <div class="col-lg-9 col-md-9 col-sm-12 lead" style="padding-right:0px;">
                     <h2 class="display-4">Abhilasha Ravichander</h2>
                     <p>
                        I am a postdoctoral scholar at the <a href="https://nlp.washington.edu/" target="_blank"> Paul G. Allen Center for Computer Science and Engineering at the University of Washington</a>.
                        I completed my PhD from <a href="https://www.cs.cmu.edu/"
                           target="_blank">Carnegie Mellon University</a>.</br></br>

                        My research focuses on building <i>trustworthy</i> language models, by:</br>
                        (1) formulating techniques to <b>rigorously diagnose and validate models and datasets</b>, </br>
                        (2) developing methods to <b>understand large language models and the mechanisms that drive their predictions</b>, and </br>
                        (3) building frameworks that enable greater <b>transparency and control for LLMs.</b></br></br>
                        
                        For more about my work, please see my <a href="#publications">publications</a>. </br> </br>

                        ✨ <b>I am on the academic job market for the 2024-2025 cycle.</b>✨  

                     </p>
                     <!--   

                                             (3) developing principles for documenting, curating and collecting datasets<b>developing princuip.</b></br></br>

                                                           <p>
                        I am a Postdoc/Young Investigator at the <a href="https://allenai.org" target="_blank">Allen Institute for AI (AI2)</a>, working on project <a target="_blank" href="https://allenai.org/commonsense/">Mosaic</a>.
                        My research focuses on building robust and generalizable systems to process natural language, by contributing techniques to diagnose and validate models, by developing stronger reasoning approaches, and by explaining the reasoning process behind model's predictive decisions.
                        </p> -->
                     <!-- where I was advised by 
                        <a target="_blank" href="https://homes.cs.washington.edu/~nasmith/">Eduard Hovy</a> and 
                        <a target="_blank" href="https://homes.cs.washington.edu/~yejin/">Norman Sadeh</a>
                         and have interned at <b>AI2</b> and <b>Microsoft Research</b>, studying how deep learning models process challenging phenomena in natural language. -->
                     <!--p
                        </p-->
                  </div>
                  <!--               <div class="col-12" style="background: white; padding: 4px; border-radius: 5px 5px; font-size: 1.15rem; font-weight: 300;">
                     <p style="margin-bottom: .5em;">
                     <em><strong>December 2021 update</strong></em>🧑‍🎓:I will likely be taking students this coming PhD application cycle. If you're interested in working with me on <em>social commonsense, social biases in language, or ethics in AI</em>, please apply to <a href="https://www.lti.cs.cmu.edu/apply-lti" target="_blank">CMU's LTI</a>.
                     </p>
                     <p style="margin-bottom: .5em;">
                     <em><strong>July 2021 update</strong></em>👨🏼‍🎓: I successfully defended my PhD thesis titled <em>Positive AI with Social Commonsense Models</em> (<a target="_blank" href="pdfs/Ravichander2021positiveAIwithSocialCommonsenseModels.pdf">read the thesis here</a>, or <a href="https://www.youtube.com/watch?v=VKd4Y7Ykh6o" target="_blank">watch the recording here<a/>). Thanks to my advisors, committee, and everyone who attended!
                     </p>
                     <p style="margin-bottom: .5em;">
                     <em><strong>May 2021 update</strong></em>🥳:  I will be joining <a href="https://www.lti.cs.cmu.edu/" target="_blank">CMU's LTI</a> department as an assistant professor👨🏼‍🏫in Fall 2022. If you wish to work with me, <a href="contact.html">see the "contact" page</a>. Before starting there, I will be a postdoc at <a href="https://allenai.org" target="_blank">AI2</a> on project <a target="_blank" href="https://allenai.org/commonsense/">Mosaic</a> 👨🏼‍🔬 starting Fall 2021.
                     </p>
                     </div> -->
               </div>
            </div>
         </div>
      </div>

   </br></br>

      <div class="container" tabindex="-1">

         <!--Navigation bar-->
         <div name="news" id="news">
            <h3>What's New</h3>
            🌴 I am speaking in a panel on "Navigating Research in the Age of LLMs" at the <a href="https://www.winlp.org/winlp-2024-workshop/">Widening NLP workshop</a> at EMNLP 2024.</a></br></br>

            ⭐ I am at the <a href="https://www.cics.umass.edu/events/rising-stars-generative-ai">"Rising Stars in Generative AI" workshop at UMass Amherst.</a></br></br>

            🏆 OLMo won the <b>ACL 2024 Best Theme Paper Award</b> 🎉 </br></br>

            🏆 Dolma won the <b>ACL 2024 Best Resource Paper Award</b> 🎉 </br></br>

            🏆 Artifacts or Abduction? won a <b>best paper award</b> at <a href="https://www.mascsll.org/cfp/">MASC-SLL 2024</a> 🎉 </br></br>

            📚 I am co-organizing the <a href="https://sites.google.com/view/privatenlp/">Workshop on Privacy in Natural Language Processing @ACL 2024</a></br></br>

            <a href="./older_news.html">Older news.</a>

            <!-- <div style="height:150px;border:1px solid #ccc;overflow:auto;">
                <div class="label-striped"><a href="https://arxiv.org/abs/2402.00838">OLMo</a> won the <b>ACL 2024 Best Theme Paper Award</b> 🎉  </div>
               <a href="https://arxiv.org/abs/2402.00159">Dolma</a> won the <b>ACL 2024 Best Resource Paper Award</b> 🎉 </br>
               <div class="label-striped"><a href="https://arxiv.org/abs/2402.12483">Artifacts or Abduction?</a> was presented at <a href="https://www.mascsll.org/cfp/">MASC-SLL 2024</a> and won a <b>best paper
                  award</b> 🎉 </div>
               I am co-organizing the <a href="https://sites.google.com/view/privatenlp/">Workshop on Privacy in Natural Language Processing @ACL 2024</a></br>
               <div class="label-striped">I co-organized the <a href="https://sites.google.com/view/repl4nlp2023">Workshop on Representation Learning for NLP @ ACL 2023</a>.  </div>
               Talk at the National University of Singapore.</br>
               <div class="label-striped">Talk at UMass NLP.  </div>
               I will be at the <a href="https://risingstars.utexas.edu/participants">Rising Stars in EECS workshop</a>
               at the University of Texas at Austin.</br>
             <div style="height:150px;border:1px solid #ccc;overflow:auto;">
                  -->

               <!-- <div class="label-striped"><a href="https://arxiv.org/abs/2211.00295">CondaQA</a> won a <b>best paper
                     award</b> at the <a href="https://socalnlp.github.io/symp22/index.html">2022 SoCal NLP
                     symposium</a> 🎉 </div>
               I was selected as a <a href="https://datascience.uchicago.edu/rising-stars-alumni/">Rising Star in Data
                  Science</a> by the University of Chicago.</br>
               <div class="label-striped">I was an outstanding reviewer at ACL 2020 and EMNLP 2020.</div>
               I started the <a href="https://nlpwithfriends.com/">NLP With Friends</a> online seminar series,
               with my wonderful co-organizers Zeerak Waseem, Yanai Elazar and Liz Salesky.</br>
               <div class="label-striped"> I will be speaking in a panel on "The Role of Active Privacy Management in a
                  World Where the
                  Consent Model Breaks Down" at <a href="https://www.cpdpconferences.org/">CPDP 2020</a> in
                  Brussels, Belgium.
               </div>
               I will be helping lead a research team at the OurCS workshop at CMU. If you are an undergraduate woman,
               please
               do consider attending! Funds for hotels and meals will be provided.</br>
               <div class="label-striped">I will be spending the summer interning at MSR Montreal with Adam Trischler
                  and Kaheer Suleman,
                  working on teaching machines commonsense reasoning.
               </div>
               I will be attending ACL, YRRSDS and SIGDIAL 2018 in Melbourne. Ping me if you'd like to
               chat!</br>
               <div class="label-striped">Our work, "Stress Test Evaluation for Natural Language Inference" was an <a
                     href="http://coling2018.org/coling-2018-best-papers/"><b>Area Chair Favorite Paper at COLING
                        2018</b></a>!
               </div>
               I will be at the <a href="https://newgeneralization.github.io/">Generalization in Deep
                  Learning</a> workshop at NAACL 2018. Ping me if you'd like to chat!</br>
               <div class="label-striped">I will be starting my PhD at the Language Technologies Institute, Carnegie
                  Mellon University in
                  Fall 2018.
               </div>
               I am at the <a href="http://mlss.tuebingen.mpg.de/2017/">Machine Learning Summer School</a> in
               Tubingen. Let me know if you'd like to meet up!</br>
               <div class="label-striped">Our team was selected to participate in the <a
                     href="https://developer.amazon.com/alexaprize">Alexa
                     Prize</a> with a 100,000$ stipend and additional support from Amazon! Congratulations to all the
                  selected teams.
               </div>
               Our work on "A Persistent Homology Approach to Document Clustering" won the best poster award in
               10-701 (Introduction to Machine Learning (PhD)).</br>
            </div> -->


            <!--       class="table table-striped"
               <table> -->
            <!--       <table>
               <tbody>
                         
                 <li> I was recognized as an outstanding reviewer at ACL 2020 and EMNLP 2020. </li>.
                       <li> I started the <a href="https://nlpwithfriends.com/">NLP With Friends</a> online seminar series, with my wonderful co-organizers Zeerak Waseem, Yanai Elazar and Liz Salesky. </li>.
               
                       <li> I will be speaking in a panel on "The Role of Active Privacy Management in a World Where the Consent Model Breaks Down" at <a href="https://www.cpdpconferences.org/">CPDP 2020</a> in Brussels, Belgium.</li>.
                       <li> I will be helping organize the OurCS workshop at CMU. If you are an undergraduate woman, please do consider attending! Funds for hotels and meals will be provided.</li>.
               
                 <li> I will be spending the summer interning at MSR Montreal with Adam Trischler and Kaheer Suleman, working on teaching machines commonsense reasoning.</li>
                 <li> I will be attending ACL, YRRSDS and SIGDIAL 2018 in Melbourne. Ping me if you'd like to chat!</li>
                 <li>Our work, "Stress Test Evaluation for Natural Language Inference" was an <a href = "http://coling2018.org/coling-2018-best-papers/">Area Chair Favorite Paper at COLING 2018</a>!  </li>
               
                 <li> I will be at the <a href = "https://newgeneralization.github.io/">Generalization in Deep Learning</a> workshop at NAACL 2018. Ping me if you'd like to chat!</li>
                 <li> I will be starting my PhD at the Language Technologies Institute, Carnegie Mellon University in Fall 2018.</li>
                <li>I am at the <a href = "http://mlss.tuebingen.mpg.de/2017/">Machine Learning Summer School</a> in Tubingen. Let me know if you'd like to meet up! </li>
               <li>Our team was selected to participate in the <a href = "https://developer.amazon.com/alexaprize">Alexa Prize</a> with a 100,000$ stipend and additional support from Amazon! Congratulations to all the selected teams.</li>
               <li>Our work on "A Persistent Homology Approach to Document Clustering" won the best poster award in 10-701 (Introduction to Machine Learning (PhD)). </li>
               <li></li>
               </tbody></table> -->
         </div>
      </div>
      <!-- </div> -->
      <!--   <div class="container"> -->
      </br>
      </br>
      <div class="container">
         (*) - Equal Contribution
         <h3>Preprints</h3>
         
         <div class="row">
            <div id="preprints">
               <span class="publications-style">
                 
                   <div class="col-sm-12">

                       <strong>HALoGEN: Fantastic LLM Hallucinations and Where To Find Them</strong><br />
                     
                     <u>Abhilasha Ravichander*</u>, Shrusti Ghela*, David Wadden, Yejin Choi<br />
                     arXiv<br />
                     <a href="https://arxiv.org/abs/2501.08292"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/AbhilashaRavichander/HALoGEN'><span class='label-code'>Code/Data</span></a>
                      <a href="https://halogen-hallucinations.github.io/"><span class="label-website">Website</span></a>
                     <span class="label-long">Long</span> </a></br></br>

                    <strong>RESTOR: Knowledge Recovery through Machine Unlearning</strong><br />
                     
                     Keivan Rezaei, Khyathi Chandu, Soheil Feizi, Yejin Choi, Faeze Brahman, <u>Abhilasha Ravichander</u><br />
                     arXiv<br />
                     <a href="https://arxiv.org/abs/2411.00204"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/k1rezaei/restor'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a></br></br>



                    <strong>WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries</strong><br />
                     
                     Wenting Zhao, Tanya Goyal, Yu Ying Chiu, Liwei Jiang, Benjamin Newman, <u>Abhilasha Ravichander</u>, Khyathi Chandu, Ronan Le Bras, Claire Cardie, Yuntian Deng, Yejin Choi<br />
                     arXiv<br />
                     <a href="https://arxiv.org/pdf/2407.17468"><span class='label-pdf'>PDF</span></a> <a
                        href='#'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a></br></br>

                  
                     





                      </div>
               </span>
            </div>
         </div>
         
          </br> </br></br> </br>
         <h3>Publications</h3>
         
         <div class="row">
            <div id="publications">
               <span class="publications-style">
                  
                  <div class="col-sm-12">
                  
            
                  <!--       1. <i>Stress Test Evaluation for
         Natural Language Inference</i></br>Abhilasha Ravichander, Aaakanksha Naik, Norman Sadeh, Carolyn Rose, Graham Neubig. </br> Workshop on New Forms of Generalizationin Deep Learning and Natural Language Processing, <i>To Appear</i>
         North American Chapter of the Association for Computational Linguistics, 2018 (NAACL-2018).</br></br> -->
                  <!--
         <div class="col-sm-1">
           2019</br></br></br></br></br>2019</br></br></br></br></br>2019</br></br></br></br></br>2019</br></br></br></br></br>2019</br></br></br></br></br>2018</br></br></br></br></br>2018</br></br></br></br></br>2017</br></br></br></br></br>2017</br></br></br></br>2017</br></br></br></br></br>2015
         </div> -->











                  
                     <!-- 1. Nishant Balepur, Abhilasha Ravichander, Rachel Rudinger
         Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?
         In preparation. [long paper] -->
                     <!-- 2. Groeneveld et al.,
         OLMo: Accelerating the Science of Language Models
         arXiv, 2024. [long paper]
         3. Soldaini et al.,
         Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research
         arXiv, 2024. [long paper] -->
                     <!-- 4. Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, Bill Yuchen Lin
         Lumos: Learning Agents with Unified Data, Modular Design, and Open-Source LLMs
         In preparation. [long paper]
         5. Yufei Tian, Abhilasha Ravichander, Lianhui Qin, Ronan Le Bras, Raja Marjieh, Nanyun Peng, Yejin Choi, Thomas L
         Griffiths, Faeze Brahman
         MacGyver: Are Large Language Models Creative Problem Solvers?
         In preparation. [long paper] -->
                     <!-- <h5><b>OLMo: Accelerating the Science of Language Models</b></h5>
         Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson, Russell Authur, Khyathi Raghavi Chandu, Arman Cohan, Jennifer Dumas, <u><i>Yanai Elazar</i></u>,
         Yuling Gu, Jack Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Valentina Pyatkin, Abhilasha Ravichander, Dustin Schwenk, Saurabh Shah, Will Smith, Emma Strubell, Nishant Subramani, Mitchell Wortsman,
           Pradeep Dasigi, Nathan Lambert, Kyle Richardson, Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca Soldaini, Noah A. Smith, Hannaneh Hajishirzi<br/>
         arxiv<br/>
         <a href="https://arxiv.org/abs/2402.00838"><span class="badge badge-pill badge-primary">paper</span></a>
         <button type="button" class="badge badge-pill badge-warning btn my-1 mr-1 btn-sm js-cite-modal" data-filename="/bibtex/olmo.bib">bibtex</button>
         <a href="https://github.com/allenai/OLMo"><span class="badge badge-pill badge-success">code</span></a>
         <a href="https://huggingface.co/datasets/allenai/dolma"><span class="badge badge-pill badge-danger">resource</span></a>
         <a href="https://huggingface.co/allenai/OLMo-7B"><span class="badge badge-pill badge-project">models</span></a>
         <br/>
         Press: <a href="https://techcrunch.com/2024/02/01/ai2-open-sources-text-generating-ai-models-and-the-data-used-to-train-them/"><span class="badge badge-pill badge-info">TechCrunch</span></a>
         <a href="https://www.axios.com/2024/02/01/allen-institute-for-ai-fully-open-source-large-language-model-olmo-7b"><span class="badge badge-pill badge-info">Axios</span></a>
         <a href="https://www.forbes.com/sites/janakirammsv/2024/02/05/how-olmo-from-the-ai2-redefines-llm-innovation/?sh=7927742b6147"><span class="badge badge-pill badge-info">Forbes</span></a>
         <a href="https://www.geekwire.com/2024/allen-institute-for-ai-promises-new-insights-into-large-language-models-with-olmo-release/"><span class="badge badge-pill badge-info">GeekWire</span></a>
         <a href="https://sdtimes.com/ai/ai2-releases-olmo-an-open-llm/"><span class="badge badge-pill badge-info">SD Times</span></a>
         <a href="https://venturebeat.com/ai/truly-open-source-llm-from-ai2-to-drive-critical-shift-in-ai-development/"><span class="badge badge-pill badge-info">VentureBeat</span></a>
         <a href="https://www.fastcompany.com/91021305/ai2-new-open-source-llm?partner=rss&utm_source=rss&utm_medium=feed&utm_campaign=rss+fastcompany&utm_content=rss"><span class="badge badge-pill badge-info">Fast Company</span></a>
      </p> -->
<!--                      <h3>2024</h3><br />
 -->
                                                                <strong>Reverse Question Answering: Can an LLM Write a Question so Hard (or Bad) that it Can't Answer?</strong><br />
                     
                     Nishant Balepur, Feng Gu, <u>Abhilasha Ravichander</u>, Shi Feng, Jordan Boyd-Graber, Rachel Rudinger<br />
                     2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2025)<br />
                     <a href="https://arxiv.org/abs/2410.15512"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/nbalepur/QG-vs-QA'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a></br></br>


                     <strong>WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild</strong><br />
                     
                     Bill Yuchen Lin, Yuntian Deng, Khyathi Chandu, Faeze Brahman, <u>Abhilasha Ravichander</u>, Valentina Pyatkin, Nouha Dziri, Ronan Le Bras, Yejin Choi<br />
                     2025 International Conference on Learning Representations, (ICLR 2025).<br />
                     <a href="https://arxiv.org/pdf/2406.04770"><span class='label-pdf'>PDF</span></a> <a
                        href='https://huggingface.co/spaces/allenai/WildBench'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a></br></br>

                     <strong>The Art of Saying No: Contextual Noncompliance in Language Models</strong><br />
                     
                     Faeze Brahman*, Sachin Kumar*, <u>Abhilasha Ravichander&#10018;</u>, Vidhisha Balachandran&#10018;, Pradeep Dasigi&#10018;, Valentina Pyatkin&#10018;, Sarah Wiegreffe&#10018;, Nouha Dziri, Khyathi Chandu, Jack Hessel, Yulia Tsvetkov, Noah A Smith, Yejin Choi, Hannaneh Hajishirzi<br />
                     NeurIPS 2024 Datasets and Benchmarks<br />
                     <a href="https://arxiv.org/pdf/2407.12043"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/allenai/noncompliance'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a></br></br>

                     <strong>Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the
                        Question?</strong><br />
                     <font color=red><i>MASC-SLL 2024 best paper award</i> </font> <br />
                     Nishant Balepur, <u>Abhilasha Ravichander</u>, Rachel Rudinger<br />
                     62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)<br />
                     <a href="https://arxiv.org/abs/2402.12483"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/nbalepur/mcqa-artifacts'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a></br></br>


                     <strong>OLMo: Accelerating the Science of Language Models</strong><br />
                     <font color=red><i>GeekWire Innovation of the Year award</i> </font>, <font color=red><i>ACL Best Theme Paper Award</i> </font> </br>
                     Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord,
                     Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson,
                     Russell Authur, Khyathi Raghavi Chandu, Arman Cohan, Jennifer Dumas, Yanai Elazar,
                     Yuling Gu, Jack Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff,
                     Aakanksha Naik, Crystal Nam, Matthew E. Peters, Valentina Pyatkin, <u>Abhilasha
                        Ravichander</u>, Dustin Schwenk, Saurabh Shah, Will Smith, Emma Strubell, Nishant
                     Subramani, Mitchell Wortsman,
                     Pradeep Dasigi, Nathan Lambert, Kyle Richardson, Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca
                     Soldaini, Noah A. Smith, Hannaneh Hajishirzi<br />
                     62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)<br />
                     <a href="https://arxiv.org/abs/2402.00838"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/allenai/OLMo'><span class='label-code'>Code/Data</span></a> <span
                        class="label-long">Long</span> </a> </br>
                     Press: <a
                        href="https://techcrunch.com/2024/02/01/ai2-open-sources-text-generating-ai-models-and-the-data-used-to-train-them/"><span
                           class="badge badge-pill badge-info">TechCrunch</span></a>
                     <a
                        href="https://venturebeat.com/ai/truly-open-source-llm-from-ai2-to-drive-critical-shift-in-ai-development/"><span
                           class="badge badge-pill badge-info">VentureBeat</span></a>
                     <a
                        href="https://www.forbes.com/sites/janakirammsv/2024/02/05/how-olmo-from-the-ai2-redefines-llm-innovation/?sh=7927742b6147"><span
                           class="badge badge-pill badge-info">Forbes</span></a>
                     <a
                        href="https://www.geekwire.com/2024/allen-institute-for-ai-promises-new-insights-into-large-language-models-with-olmo-release/"><span
                           class="badge badge-pill badge-info">GeekWire</span></a>
                     <a
                        href="https://www.axios.com/2024/02/01/allen-institute-for-ai-fully-open-source-large-language-model-olmo-7b"><span
                           class="badge badge-pill badge-info">Axios</span></a>
                     <a href="https://sdtimes.com/ai/ai2-releases-olmo-an-open-llm/"><span
                           class="badge badge-pill badge-info">SD Times</span></a>
                     <a
                        href="https://www.fastcompany.com/91021305/ai2-new-open-source-llm?partner=rss&utm_source=rss&utm_medium=feed&utm_campaign=rss+fastcompany&utm_content=rss"><span
                           class="badge badge-pill badge-info">Fast Company</span></a></br></br>




                     <strong>Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining
                        Research</strong></br>
                     <font color=red><i>ACL Best Resource Paper Award</i> </font> </br>
                     Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin Schwenk, David Atkinson, Russell Authur,
                     Ben Bogin, Khyathi Chandu, Jennifer Dumas, Yanai Elazar, Valentin Hofmann, Ananya Harsh Jha,
                     Sachin Kumar, Li Lucy, Xinxi Lyu, Nathan Lambert, Ian Magnusson,
                     Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters,
                     <u>Abhilasha Ravichander</u>, Kyle Richardson, Zejiang Shen, Emma Strubell, Nishant
                     Subramani, Oyvind Tafjord, Pete Walsh, Luke Zettlemoyer, Noah A. Smith, Hannaneh Hajishirzi,
                     Iz Beltagy, Dirk Groeneveld, Jesse Dodge, Kyle Lo<br />
                     62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)<br />
                     <a href="https://arxiv.org/abs/2402.00159"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/allenai/dolma'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a> </br>
                     Press: <a
                        href="https://techcrunch.com/2023/08/18/ai2-drops-biggest-open-dataset-yet-for-training-language-models/"><span
                           class="badge badge-pill badge-info">TechCrunch</span></a>
                     <a
                        href="https://www.marktechpost.com/2023/08/23/ai2-unveils-dolma-a-3-trillion-token-corpus-pioneering-transparency-in-language-model-research/"><span
                           class="badge badge-pill badge-info">Marktechpost</span></a>
                     <a
                        href="https://voicebot.ai/2023/08/22/allen-institute-for-ai-releases-largest-open-text-dataset-ever-to-boost-ai-research-transparency/"><span
                           class="badge badge-pill badge-info">Voicebot</span></a>
                     </br></br>





                     <strong>Agent Lumos: Unified and Modular Training for Open-Source Language
                        Agents</strong></br>
                     Da Yin, Faeze Brahman, <u>Abhilasha Ravichander</u>, Khyathi Chandu, Kai-Wei Chang, Yejin
                     Choi, Bill Yuchen Lin<br />
                     62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)<br />
                     <a href="https://arxiv.org/abs/2311.05657"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/allenai/lumos'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a> <a href="https://allenai.github.io/lumos/"><span
                           class="label-website">Website</span></a> </br>
                     Press: <a
                        href="https://www.marktechpost.com/2024/04/01/lumos-an-open-source-generalizable-language-agent-training-framework/"><span
                           class="badge badge-pill badge-info">Marktechpost</span></a>

                     </br></br>




                     <strong>MacGyver: Are Large Language Models Creative Problem Solvers?</strong></br>
                     Yufei Tian, <u>Abhilasha Ravichander</u>, Lianhui Qin, Ronan Le Bras, Raja Marjieh, Nanyun
                     Peng, Yejin Choi, Thomas L
                     Griffiths, Faeze Brahman<br />
                     2024 Annual Conference of the North American Chapter of the Association for Computational
                     Linguistics (NAACL 2024) <br />
                     <a href="https://arxiv.org/abs/2311.09682"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/allenai/MacGyver'><span class='label-code'>Code/Data</span></a> <span
                        class="label-long">Long</span> </a>
                     </br></br>



                     <strong>What’s In My Big Data?</strong> </br>
                     <font color=red><i>Spotlight</i></font></br>
                     Yanai Elazar, Akshita Bhagia, Ian Magnusson, <u>Abhilasha Ravichander</u>, Dustin Schwenk,
                     Alane Suhr, Evan Pete Walsh,
                     Dirk Groeneveld, Luca Soldaini, Sameer Singh, Hannaneh Hajishirzi, Noah A. Smith, Jesse
                     Dodge</br>
                     2024 International Conference on Learning Representations, (ICLR 2024). </br>
                     <a href="https://arxiv.org/abs/2310.20707"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/allenai/wimbd'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a><a href="https://wimbd.apps.allenai.org/"><span
                           class="label-website">Website</span></a> </br>
                     Press: <a
                        href="https://www.marktechpost.com/2023/11/05/peeking-inside-pandoras-box-unveiling-the-hidden-complexities-of-language-model-datasets-with-whats-in-my-big-data-wimbd/"><span
                           class="badge badge-pill badge-info">Marktechpost</span></a>
                     </br></br>


                     <strong>The Generative AI Paradox: “What It Can Create, It May Not
                        Understand”</strong></br>
                     Peter West, Ximing Lu, Nouha Dziri, Faeze Brahman, Linjie Li, Jena D. Hwang, Liwei Jiang,
                     Jillian Fisher, <u>Abhilasha
                        Ravichander</u>, Khyathi Chandu, Benjamin Newman, Pang Wei Koh, Allyson Ettinger, Yejin
                     Choi</br>
                     2024 International Conference on Learning Representations, (ICLR 2024). <br />
                     <a href="https://arxiv.org/abs/2311.00059"><span class='label-pdf'>PDF</span></a> <span
                        class="label-long">Long</span> </a> </br></br>


                     <strong>The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context
                        Learning</strong></br>
                     Bill Yuchen Lin, <u>Abhilasha Ravichander</u>, Ximing Lu, Nouha Dziri, Melanie Sclar,
                     Khyathi Chandu, Chandra Bhagavatula,
                     Yejin Choi </br>
                     2024 International Conference on Learning Representations, (ICLR 2024). <br />
                     <a href="https://arxiv.org/abs/2312.01552"><span class='label-pdf'>PDF</span></a> <a
                        href='https://github.com/Re-Align/urial'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a> <a href="https://allenai.github.io/re-align/"><span
                           class="label-website">Website</span></a></br></br>

                     <strong>Understanding How to Inform Blind and Low-Vision Users about Data Privacy through
                        Privacy Question Answering Assistants</strong></br>
                     Yuanyuan Feng, <u>Abhilasha Ravichander</u>, Yaxing Yao, Shikun Zhang, Rex Chen, Shomir
                     Wilson, Norman Sadeh</br>
                     USENIX Security 2024. </br>
                     <a href="https://arxiv.org/abs/2310.08687"><span class='label-pdf'>PDF</span></a> <span
                        class="label-long">Long</span><hr>

<!--                      <h3>2023</h3></br> -->

                     <strong>Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without
                        Fine-tuning</strong></br>
                     Ximing Lu, Faeze Brahman, Peter West, Jaehun Jang, Khyathi Chandu, <u>Abhilasha
                        Ravichander</u>, Lianhui Qin, Prithviraj
                     Ammanabrolu, Liwei Jiang, Sahana Ramnath, Nouha Dziri, Jillian Fisher, Bill Yuchen Lin,
                     Skyler Hallinan, Xiang Ren, Sean
                     Welleck, Yejin Choi </br>
                     2023 Conference on Empirical Methods in Natural Language Processing, (EMNLP 2023). </br>
                     <a href="https://arxiv.org/abs/2305.15065"><span class='label-pdf'>PDF</span></a> <a
                        href="https://github.com/GXimingLu/IPA"><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span>
                     <!-- <span class="label-slides">Slides</span> --></br></br>




            <strong>When and Why Does Bias Mitigation Work?</strong></br>
            <u>Abhilasha Ravichander</u>*, Joe Stacey*, Marek Rei </br>
            Findings of the 2023 Conference on Empirical Methods in Natural Language Processing,
            (EMNLP Findings 2023). </br>
            <a href="https://arxiv.org/abs/2211.00295"><span class='label-pdf'>PDF</span></a> <a
               href='https://github.com/AbhilashaRavichander/CondaQA'><span class='label-code'>Code/Data</span></a>
            <span class="label-long">Long</span>
            <!-- <span class="label-slides">Slides</span> --></br></br>
            <hr>

<!--             <h3>2022</h3></br> -->
            <strong>CondaQA: A Contrastive Reading Comprehension Dataset for Reasoning about
               Negation</strong> </br>
            <font color=red><i>SoCal NLP Symposium best paper award</i> </font> </br>
            <u>Abhilasha Ravichander</u>, Matt Gardner, Ana Marasović </br>
            2022 Conference on Empirical Methods in Natural Language Processing, (EMNLP 2022).</br>
            <a href="https://aclanthology.org/2023.findings-emnlp.619/"><span class='label-pdf'>PDF</span></a> <span
               class='label-code'>Code/Data</span> <span class="label-long">Long</span>
            <!-- <span class="label-slides">Slides</span> --></br></br>

            <strong>Measuring Causal Effects of Data Statistics on Language Model's `Factual'
               Predictions</strong></br>
            Yanai Elazar, Nora Kassner, Shauli Ravfogel, Amir Feder, <u>Abhilasha Ravichander</u>,
            Marius Mosbach, Yonatan Belinkov, Hinrich Schütze, Yoav Goldberg </br>
            Preprint.</br>
            <a href="https://arxiv.org/abs/2207.14251"><span class='label-pdf'>PDF</span></a>
            </br></br>


            <strong>A Tale of Two Regulatory Regimes: Creation and Analysis of a Bilingual Privacy
               Policy Corpus</strong></br>
            Siddhant Arora, Henry Hosseini, Christine Utz, Vinayshekhar Bannihatti Kumar, Tristan
            Dhellemmes, <u>Abhilasha Ravichander</u>, Peter Story, Jasmine Mangat, Rex Chen, Martin
            Degeling, Thomas Norton, Thomas Hupperich, Shomir Wilson, Norman Sadeh </br>
            Thirteenth Language Resources and Evaluation Conference, (LREC 2022).</br>
            <a href="https://aclanthology.org/2022.lrec-1.585/"><span class='label-pdf'>PDF</span></a>
            <a href='https://usableprivacy.org/data'><span class='label-code'>Code/Data</span></a>
            <span class="label-long">Long</span>
            <!-- <span class="label-slides">Slides</span> --><hr>


<!--             <h3>2021</h3></br> -->


                  <strong>Probing the Probing Paradigm: Does Probing Accuracy Entail Task
                     Relevance?</strong></br>
                  <u>Abhilasha Ravichander</u>, Yonatan Belinkov, Eduard Hovy </br>
                  16th Conference of the European Chapter of the Association for Computational Linguistics,
                  (EACL 2021).</br>
                  <a href="https://arxiv.org/abs/2005.00719"><span class='label-pdf'>PDF</span></a> <a href='#'><span
                        class='label-code'>Code/Data</span></a> <span class="label-long">Long</span>
                  <!-- <span class="label-slides">Slides</span> --></br></br>

                  <strong>NoiseQA: Challenge Set Evaluation for User-Centric Question
                     Answering</strong></br>
                  <u>Abhilasha Ravichander</u>, Siddharth Dalmia, Maria Ryskina, Florian Metze, Eduard Hovy,
                  Alan W Black </br>
                  16th Conference of the European Chapter of the Association for Computational Linguistics,
                  (EACL 2021).</br>
                  <a href="https://arxiv.org/abs/2102.08345"><span class='label-pdf'>PDF</span></a> <a
                     href='https://github.com/noiseQA/NoiseQA'><span class='label-code'>Code/Data</span></a>
                  <span class="label-long">Long</span> <a href='https://noiseqa.github.io/'><span
                        class="label-website">Website</span></a>
                  <!-- <span class="label-slides">Slides</span> --></br></br>

                  <strong>Measuring and Improving Consistency in Pretrained Language Models</strong></br>
                  Yanai Elazar, Nora Kassner, Shauli Ravfogel, <u>Abhilasha Ravichander</u>, Eduard Hovy,
                  Hinrich Schütze, Yoav Goldberg </br>
                  Transactions of the Association of Computational Linguistics, (TACL 2021).</br>
                  <a href="https://arxiv.org/abs/2102.01017"><span class='label-pdf'>PDF</span></a> <a
                     href='https://github.com/yanaiela/pararel'><span class='label-code'>Code/Data</span></a> <span
                     class="label-long">Long</span>
                  </br></br>

                  <strong>Breaking Down Walls of Text: How Can NLP Benefit Consumer Privacy?</strong></br>
                  <u>Abhilasha Ravichander</u>, Alan W Black, Thomas Norton, Shomir Wilson and Norman
                  Sadeh.</br>
                  59th Annual Meeting of the Association for Computational Linguistics, (ACL 2021) </br>
                  <a href=""><span class='label-pdf'>PDF</span></a> <span class="label-long">Long</span>
                  <hr>

<!--             <h3>2020</h3></br>   -->
                  <strong>On the Systematicity of Probing Contextualized Word Representations: The Case of
                     Hypernymy in BERT</strong></br>
                  <u>Abhilasha Ravichander</u>, Eduard Hovy, Kaheer Suleman, Adam Trischler, Jackie Chi Kit
                  Cheung. </br>
                  2020 Joint Conference on Lexical and Computational Semantics, (*SEM 2020). </br>
                  <a href="https://www.aclweb.org/anthology/2020.starsem-1.10/"><span class='label-pdf'>PDF</span></a>
                  <a href='https://github.com/AbhilashaRavichander/probe-generalization'><span
                        class='label-code'>Code/Data</span></a> <span class="label-long">Long</span>
                  <hr>
<!--             <h3>2019</h3></br>   -->
                  <strong>EQUATE: A Benchmark Evaluation Framework for Quantitative Reasoning in Natural
                     Language Inference</strong></br>
                  <u>Abhilasha Ravichander*</u>, Aakanksha Naik*, Carolyn Rose, Eduard Hovy </br>
                  2019 Conference on Computational Natural Language Learning, (CoNLL 2019).</br>
                  <a href="https://arxiv.org/abs/1901.03735"><span class='label-pdf'>PDF</span></a> <a
                     href='https://github.com/AbhilashaRavichander/EQUATE'><span class='label-code'>Code/Data</span></a>
                  <span class="label-long">Long</span></br></br>

                  <strong>Question Answering for Privacy Policies: Combining Computational and Legal
                     Perspectives</strong></br>
                  <u>Abhilasha Ravichander</u>, Alan W Black, Shomir Wilson, Thomas Norton and Norman
                  Sadeh.</br>
                  2019 Conference on Empirical Methods in Natural Language Processing, (EMNLP 2019) </br>
                  <a href="https://www.aclweb.org/anthology/D19-1500/"><span class='label-pdf'>PDF</span></a> <a
                     href='https://github.com/AbhilashaRavichander/PrivacyQA/'><span
                        class='label-code'>Code/Data</span></a> <span class="label-long">Long</span>
                  </br></br>

                  <strong>Exploring Numeracy in Word Embeddings</strong></br>Aakanksha Naik*, <u>Abhilasha
                     Ravichander*</u>, Carolyn Rose, Eduard Hovy </br>
                  57th Meeting of Association for Computational Linguistics, (ACL
                  2019).&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</br>
                  <a href="https://arxiv.org/abs/1806.00692"><span class='label-pdf'>PDF</span></a> <span
                     class="label-short">Short</span> </br></br>

                  <strong>Evaluating How Global Privacy Principles Answer Consumers’ Questions About Mobile
                     App Privacy.</strong></br>
                  Thomas Norton, Joel Reidenberg, Norman Sadeh and <u>Abhilasha Ravichander</u></br>
                  4th European Privacy Law Scholars Conference, (PLSC 2019).</br></br>

                  <strong>Challenges in Automated Question Answering for Privacy Policies.</strong></br>
                  <u>Abhilasha Ravichander</u>, Alan Black, Eduard Hovy, Joel Reidenberg, N. Cameron Russell
                  and Norman Sadeh</br>
                  AAAI Spring Symposium Series, 2019</br>
                  <a href="http://ceur-ws.org/Vol-2335/1st_PAL_paper_13.pdf"><span class='label-pdf'>PDF</span></a>
                  <span class="label-long">Long</span> </br></br>

                  <strong>MAPS: Scaling Privacy Compliance Analysis to a Million Apps</strong></br>
                  Peter Story, Sebastian Zimmeck, Daniel Smullen, <u>Abhilasha Ravichander</u>, Ziqi Wang,
                  Joel Reidenberg, N. Cameron Russell and Norman Sadeh </br>
                  PETS 2019 </br>
                  <a href="https://content.sciendo.com/view/journals/popets/2019/3/article-p66.xml?tab_body=pdf"><span
                        class='label-pdf'>PDF</span></a> <span class="label-long">Long</span> 
<hr>
<!--          <h3>2018</h3></br> -->
                  <strong>Stress Test Evaluation for Natural Language Inference</strong> </br> <font color=red>
                     <i>Area Chair Favorite Paper Prize</i> </font> </br>
                  Aakanksha Naik*, <u>Abhilasha Ravichander*</u>, Norman Sadeh, Carolyn Rose, Graham Neubig.
                  </br>
                  <i>27th International Conference on Computational Linguistics</i>, (COLING 2018). </br>
                  <a href="https://arxiv.org/abs/1806.00692"><span class='label-pdf'>PDF</span></a> <a
                     href='https://abhilasharavichander.github.io/NLI_StressTest/'><span
                        class='label-code'>Code/Data</span></a> <span class="label-long">Long</span> <a
                     href='https://abhilasharavichander.github.io/NLI_StressTest/'> <span
                        class="label-website">Website</span></a> <a
                     href='https://github.com/AbhilashaRavichander/NLI_StressTest/blob/master/slides.pdf'><span
                        class="label-slides">Slides</span></a></br></br>

            <!-- <div class="row">
                           <div class="col-sm-1">
                              2018
                           </div>
                           <div class="col-sm-11">
                              <strong>An Empirical Study of Self-Disclosure in Spoken Dialogue Systems</strong></br>
                              <u>Abhilasha Ravichander</u>, Alan Black. </br>
                              <i>19th Annual SIGdial Meeting on Discourse and Dialogue</i>, (SIGDIAL 2018). </br>
                              <a href="http://aclweb.org/anthology/W18-5030"><span class='label-pdf'>PDF</span></a><span class="label-long">Long</span> </br></br>
                           </div>
                        </div> -->

                  <strong>An Empirical Study of Self-Disclosure in Spoken Dialogue Systems</strong></br>
                  <u>Abhilasha Ravichander</u>, Alan Black. </br>
                  <i>19th Annual SIGdial Meeting on Discourse and Dialogue</i>, (SIGDIAL
                  2018).&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  </br>
                  <a href="http://aclweb.org/anthology/W18-5030"><span class='label-pdf'>PDF</span></a><span
                     class="label-long">Long</span> 
                  </br></br>
                  <hr>
<!--                   <h3>2017</h3></br>                -->
                  <strong>Does the Geometry of Word Embeddings Help Document Classification? A Case Study on
                     Persistent Homology-Based Representations</strong></br>
                  Paul Michel*, <u>Abhilasha Ravichander*</u>, Shruti Rijhwani*.</br>
                  <i>Workshop on Representation Learning For NLP</i>, Association for Computational
                  Linguistics, 2017 (ACL 2017). </br>
                  <a href="http://www.aclweb.org/anthology/W17-2628"><span class='label-pdf'>PDF</span></a>
                  <span class="label-short">Short</span></br></br>

                  <strong>How Would You Say It? Eliciting Lexically Diverse Data for Supervised Semantic
                     Parsing</strong></br>
                  <u>Abhilasha Ravichander*</u>, Thomas Manzini*, Matthias Grabmair, Jonathan Francis,
                  Graham Neubig, Eric Nyberg. </br>
                  <i>18th Annual SIGdial Meeting on Discourse and Dialogue</i>, (SIGDIAL 2017).</br> <a
                     href="http://aclweb.org/anthology/W17-5545"><span class='label-pdf'>PDF</span></a> <a
                     href='https://github.com/oaqa/resources'><span class='label-code'>Code/Data</span></a>
                  <span class="label-long">Long</span> </br></br>

         </div>



         <!--      <h3 id="service">Service</h3>-->
         <!--         <ul>-->
         <!--<li>  Area Chair, ACL 2023</li>-->
         <!--<li> Area Chair, EMNLP 2022</li>-->
         <!--<li> NAACL DEI Socio-Cultural Inclusion Chair, NAACL 2022</li>-->
         <!--<li> Started <a href="https://nlpwithfriends.com/">NLP with Friends</a> with wonderful fellow organizers: Yanai Elazar, Elizabeth Salesky and Zeerak Waseem!</li>-->
         <!--<li> Reviewer-->
         <!--Conferences: NAACL-HLT 2019, ACL 2020, EMNLP 2020, EACL 2021, ACL 2021, ACL Rolling Review 2021, ACL-->
         <!--Rolling Review 2022-->
         <!--Workshops: ACL SRW 2020, AACL-IJCNLP SRW 2020, EMNLP-SDP 2020, Neurips HAMLETS workshop 2020,-->
         <!--RepL4NLP 2021, AmericasNLP 2021, BlackboxNLP 2021, ACL SRW 2022, Blackbox NLP 2022</li>-->
         <!--<li> Student Volunteer, NAACL-HLT, 2019, EMNLP 2019</li>-->
         <!--<li> Session Chair, AAAI Spring Symposium Series, 2019</li>-->
         <!--<li> CMU AI Research mentor (initiative to mentor under-represented minorities in Computer Science)</li>-->
         <!--<li>  Research Team Lead, OurCS 2019 (workshop to introduce undergraduate women to computer science research)</li>-->
         <!--<li> Program Committee, CMU LTI Student Research Symposium 2018.</li>-->
         <!--<li>  Student Volunteer, Widening NLP Workshop at NAACL-HLT 2018.</li>-->
         <!--<ul>-->
         <!--      <h3>Talks</h3>-->

         <!--      <h3>Misc</h3>-->
</body>
<style>
   .card {
      padding: 0px;
      margin: 10px 5px;
   }

   .card-img-top {
      max-height: 170px;
      max-width: 70%;
      width: auto;
      margin-left: 1em;
      margin-right: 1em;
   }

   .btn {
      margin-top: .2em;
   }

   .profile {
      border-radius: .1em;
      box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);
   }
</style>

</html>
