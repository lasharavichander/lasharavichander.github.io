<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abhilasha Ravichander</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <script src="https://kit.fontawesome.com/08daa0274c.js" crossorigin="anonymous"></script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">

<!-- <style>
  body {
    font-family: 'Inter', sans-serif;
  }
</style> -->
<style>
    body {
      font-family: 'Roboto', sans-serif;
      font-weight: 400;
      line-height: 1.6;
    }
  
    h1, h2, h3, h4, h5, h6 {
      font-weight: 500;
    }
  
    strong, b {
      font-weight: 700;
    }
  
    .light {
      font-weight: 300;
    }
  </style>
  <!-- <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet"> -->
  <style>
    .label-dataset {
       background-color: #9b59b6;
    }

    .label-dataset[href]:hover,
    .label-dataset[href]:focus {
       background-color: #8e44ad;
    }

    .label-video {
       background-color: #ffcccc;
    }

    .label-best {
       background-color: #99004d;
    }

    .label-short {
       background-color: #d27979;
    }

    .label-long {
       background-color: #26004d;
    }


    .label-pdf {
       background-color: #643191;
       color: white;
       padding: 2px;
       margin-left: 1px;
       margin-right: 1px;
    }

    .label-code {
       background-color: #4350c6;
       color: white;
       padding: 2px;
       margin-left: 1px;
       margin-right: 1px;
    }

    .label-slides {
       background-color: #317d91;
       color: white;
       padding: 2px;
       margin-left: 1px;
       margin-right: 1px;
    }

    .label-website {
       background-color: #99004d;
       color: white;
       padding: 2px;
       margin-left: 1px;
       margin-right: 1px;
    }

    .label-short {
       background-color: #076b3e;
       color: white;
       padding: 2px;
       margin-left: 1px;
       margin-right: 1px;
    }

    .label-long {
       background-color: #379138;
       color: white;
       padding: 2px;
       margin-left: 1px;
       margin-right: 1px;
    }
 </style>

  <style>
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }
    body {
      font-family: 'Inter', sans-serif;
      background-color: #f9fafb;
      color: #111827;
      line-height: 1.6;
    }
    header {
      background-color: #ffffff;
      color: #111827;
      padding: 1rem 2rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
      box-shadow: 0 2px 4px rgba(0,0,0,0.05);
      position: sticky;
      top: 0;
      z-index: 1000;
    }
    header h1 {
      font-size: 1.2rem;
      font-weight: 700;
    }
    nav {
      display: flex;
      gap: 1.5rem;
    }
    nav a {
      color: #111827;
      text-decoration: none;
      font-weight: 500;
      transition: color 0.2s;
    }
    nav a:hover {
      color: #3b82f6;
    }
    .intro {
      display: flex;
      align-items: center;
      justify-content: center;
      flex-wrap: wrap;
      gap: 2rem;
      padding: 3rem 1rem 2rem;
      max-width: 900px;
      margin: 0 auto;
    }
    .intro img {
      width: 180px;
      height: 180px;
      border-radius: 9999px;
      object-fit: cover;
      box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .intro-text {
      flex: 1;
      min-width: 250px;
    }
    .intro-text h2 {
      font-size: 1.8rem;
      margin-bottom: 0.5rem;
    }
    .intro-text p {
      font-size: 1rem;
      color: #374151;
    }
    main {
      max-width: 900px;
      margin: 0rem auto;
    }
    section {
      margin-bottom: 0rem;
    }
    section h2 {
      font-size: 1.5rem;
      /* border-bottom: 2px solid #e5e7eb;
      padding-bottom: 0.5rem;
      margin-bottom: 1rem; */
    }
    .pub {
      margin-bottom: 1rem;
    }
    footer {
      text-align: center;
      padding: 2rem;
      color: #6b7280;
      font-size: 0.9rem;
    }
    a {
      color: #3b82f6;
    }
    .content {
  width: 80%;
  margin: 0 auto; /* Centers the container horizontally */
}
  </style>
</head>
<body>
  <header>
    <!-- <h1>Abhilasha Ravichander</h1> -->
    <h1>
        <span style="font-weight: 400;">Abhilasha</span>
        <span style="font-weight: 400;">Ravichander</span>
      </h1>
      <nav>
        <a href="./index.html">Home</a>
        <a href="./publications.html">Publications</a>
        <a href="./contact.html">Contact</a>
        <a href="./talks.html">Short Bio</a>
      </nav>
  </header>


<div class="content">

      <h2>Publications </h2>
      <p>"*" denotes equal contribution</p></br>



         
          <div class="row">
             
                <span class="publications-style">
                   
                   <div class="col-sm-12">
                   
 
 
 
 
 
 
 
 
 
 
                   
                      <!-- 1. Nishant Balepur, Abhilasha Ravichander, Rachel Rudinger
          Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?
          In preparation. [long paper] -->
                      <!-- 2. Groeneveld et al.,
          OLMo: Accelerating the Science of Language Models
          arXiv, 2024. [long paper]
          3. Soldaini et al.,
          Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research
          arXiv, 2024. [long paper] -->
                      <!-- 4. Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, Bill Yuchen Lin
          Lumos: Learning Agents with Unified Data, Modular Design, and Open-Source LLMs
          In preparation. [long paper]
          5. Yufei Tian, Abhilasha Ravichander, Lianhui Qin, Ronan Le Bras, Raja Marjieh, Nanyun Peng, Yejin Choi, Thomas L
          Griffiths, Faeze Brahman
          MacGyver: Are Large Language Models Creative Problem Solvers?
          In preparation. [long paper] -->
                      <!-- <h5><b>OLMo: Accelerating the Science of Language Models</b></h5>
          Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson, Russell Authur, Khyathi Raghavi Chandu, Arman Cohan, Jennifer Dumas, <u><i>Yanai Elazar</i></u>,
          Yuling Gu, Jack Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Valentina Pyatkin, Abhilasha Ravichander, Dustin Schwenk, Saurabh Shah, Will Smith, Emma Strubell, Nishant Subramani, Mitchell Wortsman,
            Pradeep Dasigi, Nathan Lambert, Kyle Richardson, Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca Soldaini, Noah A. Smith, Hannaneh Hajishirzi<br/>
          arxiv<br/>
          <a href="https://arxiv.org/abs/2402.00838"><span class="badge badge-pill badge-primary">paper</span></a>
          <button type="button" class="badge badge-pill badge-warning btn my-1 mr-1 btn-sm js-cite-modal" data-filename="/bibtex/olmo.bib">bibtex</button>
          <a href="https://github.com/allenai/OLMo"><span class="badge badge-pill badge-success">code</span></a>
          <a href="https://huggingface.co/datasets/allenai/dolma"><span class="badge badge-pill badge-danger">resource</span></a>
          <a href="https://huggingface.co/allenai/OLMo-7B"><span class="badge badge-pill badge-project">models</span></a>
          <br/>
          📰 Press: <a href="https://techcrunch.com/2024/02/01/ai2-open-sources-text-generating-ai-models-and-the-data-used-to-train-them/"><span class="badge badge-pill badge-info">TechCrunch</span></a>
          <a href="https://www.axios.com/2024/02/01/allen-institute-for-ai-fully-open-source-large-language-model-olmo-7b"><span class="badge badge-pill badge-info">Axios</span></a>
          <a href="https://www.forbes.com/sites/janakirammsv/2024/02/05/how-olmo-from-the-ai2-redefines-llm-innovation/?sh=7927742b6147"><span class="badge badge-pill badge-info">Forbes</span></a>
          <a href="https://www.geekwire.com/2024/allen-institute-for-ai-promises-new-insights-into-large-language-models-with-olmo-release/"><span class="badge badge-pill badge-info">GeekWire</span></a>
          <a href="https://sdtimes.com/ai/ai2-releases-olmo-an-open-llm/"><span class="badge badge-pill badge-info">SD Times</span></a>
          <a href="https://venturebeat.com/ai/truly-open-source-llm-from-ai2-to-drive-critical-shift-in-ai-development/"><span class="badge badge-pill badge-info">VentureBeat</span></a>
          <a href="https://www.fastcompany.com/91021305/ai2-new-open-source-llm?partner=rss&utm_source=rss&utm_medium=feed&utm_campaign=rss+fastcompany&utm_content=rss"><span class="badge badge-pill badge-info">Fast Company</span></a>
       </p> -->
 <!--                      <h3>2024</h3><br />
  -->

                     
<strong>The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage<strong><br />
Skyler Hallinan, Jaehun Jung, Melanie Sclar, Ximing Lu, <u>Abhilasha Ravichander</u>, Sahana Ramnath, Yejin Choi, Sai Praneeth Karimireddy, Niloofar Mireshghallah, Xiang Ren<br />
2025 Conference on Language Modeling (COLM 2025)<br />
 <a href="https://www.arxiv.org/pdf/2508.09603"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/shallinan1/NGramCoverageAttack'><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span> </a><br /><br />
                      
                        <strong>HALoGEN: Fantastic LLM Hallucinations and Where To Find Them</strong><br />
                        🏆 <font color=red><i>ACL Outstanding Paper Award</i></font> and <font color=red><i>TrustNLP Workshop best paper award</i></font><br />
                      
                      <u>Abhilasha Ravichander*</u>, Shrusti Ghela*, David Wadden, Yejin Choi<br />
 <!--                      arxiv <br /> -->
                      2025 Annual Conference of the Association for Computational Linguistics (ACL 2025)<br />
                      <a href="https://arxiv.org/abs/2501.08292"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/AbhilashaRavichander/HALoGEN'><span class='label-code'>Code/Data</span></a>
                       <a href="https://halogen-hallucinations.github.io/"><span class="label-website">Website</span></a>
                      <span class="label-long">Long</span> </a><br /><br />
                      
                                                                 <strong>Information-Guided Identification of Training Data Imprint in (Proprietary) Large Language Models</strong><br />
                      
                      <u>Abhilasha Ravichander</u>, Jillian Fisher, Taylor Sorensen, Ximing Lu, Maria Antoniak, Bill Yuchen Lin, Niloofar Mireshghallah, Chandra Bhagavatula, Yejin Choi<br />
                      2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2025)<br />
                     <a href="https://arxiv.org/abs/2503.12072"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/AbhilashaRavichander/information-probing'><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span> </a><br />
                                           📰 Press: <a
                         href="https://techcrunch.com/2025/04/04/openais-models-memorized-copyrighted-content-new-study-suggests/"><span
                            class="badge badge-pill badge-info">Techcrunch</span></a> <a
                         href="https://www.livemint.com/mint-lounge/business-of-life/ai-tracker-ai-news-ethics-grok-climate-change-ai-avatar-new-york-court-11743855910599.html"><span
                            class="badge badge-pill badge-info">Mint</span></a>
                   <br /><br />
 
                   <strong>RESTOR: Knowledge Recovery through Machine Unlearning</strong><br />
                      
                   Keivan Rezaei, Khyathi Chandu, Soheil Feizi, Yejin Choi, Faeze Brahman, <u>Abhilasha Ravichander</u><br />
                   Transactions on Machine Learning Research (TMLR 2025)<br />
                   <a href="https://arxiv.org/abs/2411.00204"><span class='label-pdf'>PDF</span></a> <a
                      href='https://github.com/k1rezaei/restor'><span class='label-code'>Code/Data</span></a>
                   <span class="label-long">Long</span> </a><br /><br />

                   <strong>
                    Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations</strong><br />
                      
                    Yiyou Sun, Yu Gai, Lijie Chen, <u>Abhilasha Ravichander</u>, Yejin Choi, Dawn Song<br />
                   arxiv<br />
                  <a href="https://arxiv.org/abs/2504.12691"><span class='label-pdf'>PDF</span></a>
                   <a
                   href='https://github.com/sunyiyou/SAT'><span class='label-code'>Code/Data</span></a> <span class="label-long">Long</span><br /><br />
                                         
                   <strong>What Has Been Lost with Synthetic Evaluation?</strong><br />
                      
                   Alex Gill, <u>Abhilasha Ravichander</u>, Ana Marasović<br />
                   arxiv<br />
                  <a href="https://arxiv.org/abs/2505.22830"><span class='label-pdf'>PDF</span></a>
                   <span class="label-long">Long</span> </a><br />

                <br />
                      
 
                                                                 <strong>Reverse Question Answering: Can an LLM Write a Question so Hard (or Bad) that it Can't Answer?</strong><br />
                      
                      Nishant Balepur, Feng Gu, <u>Abhilasha Ravichander</u>, Shi Feng, Jordan Boyd-Graber, Rachel Rudinger<br />
                      2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2025)<br />
                      <a href="https://arxiv.org/abs/2410.15512"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/nbalepur/QG-vs-QA'><span class='label-code'>Code/Data</span></a>
                      <span class="label-short">Short</span><br /><br />
 
                      
 

 
                      <strong>WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild</strong><br />
                      <font color=red><i>Spotlight</i></font><br />
                      
                      Bill Yuchen Lin, Yuntian Deng, Khyathi Chandu, Faeze Brahman, <u>Abhilasha Ravichander</u>, Valentina Pyatkin, Nouha Dziri, Ronan Le Bras, Yejin Choi<br />
                      2025 International Conference on Learning Representations (ICLR 2025).<br />
                      <a href="https://arxiv.org/pdf/2406.04770"><span class='label-pdf'>PDF</span></a> <a
                         href='https://huggingface.co/spaces/allenai/WildBench'><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span> </a><br /><br />
 
 

                      <strong>The Art of Saying No: Contextual Noncompliance in Language Models</strong><br />
                      
                      Faeze Brahman*, Sachin Kumar*, <u>Abhilasha Ravichander&#10018;</u>, Vidhisha Balachandran&#10018;, Pradeep Dasigi&#10018;, Valentina Pyatkin&#10018;, Sarah Wiegreffe&#10018;, Nouha Dziri, Khyathi Chandu, Jack Hessel, Yulia Tsvetkov, Noah A Smith, Yejin Choi, Hannaneh Hajishirzi<br />
                      NeurIPS 2024 Datasets and Benchmarks<br />
                      <a href="https://arxiv.org/pdf/2407.12043"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/allenai/noncompliance'><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span> </a><br /><br />
 
                      <strong>Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the
                         Question?</strong><br />
                      🏆 <font color=red><i>MASC-SLL 2024 best paper award</i> </font> <br />
                      Nishant Balepur, <u>Abhilasha Ravichander</u>, Rachel Rudinger<br />
                      62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)<br />
                      <a href="https://arxiv.org/abs/2402.12483"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/nbalepur/mcqa-artifacts'><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span> </a><br /><br />
 
 
                      <strong>OLMo: Accelerating the Science of Language Models</strong><br />
                      🏆 <font color=red><i>GeekWire Innovation of the Year award</i> </font>, <font color=red><i>ACL Best Theme Paper Award</i> </font> <br />
                      Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord,
                      Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson,
                      Russell Authur, Khyathi Raghavi Chandu, Arman Cohan, Jennifer Dumas, Yanai Elazar,
                      Yuling Gu, Jack Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff,
                      Aakanksha Naik, Crystal Nam, Matthew E. Peters, Valentina Pyatkin, <u>Abhilasha
                         Ravichander</u>, Dustin Schwenk, Saurabh Shah, Will Smith, Emma Strubell, Nishant
                      Subramani, Mitchell Wortsman,
                      Pradeep Dasigi, Nathan Lambert, Kyle Richardson, Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca
                      Soldaini, Noah A. Smith, Hannaneh Hajishirzi<br />
                      62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)<br />
                      <a href="https://arxiv.org/abs/2402.00838"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/allenai/OLMo'><span class='label-code'>Code/Data</span></a> <span
                         class="label-long">Long</span> </a> <br />
                      📰 Press: <a
                         href="https://techcrunch.com/2024/02/01/ai2-open-sources-text-generating-ai-models-and-the-data-used-to-train-them/"><span
                            class="badge badge-pill badge-info">TechCrunch</span></a>
                      <a
                         href="https://venturebeat.com/ai/truly-open-source-llm-from-ai2-to-drive-critical-shift-in-ai-development/"><span
                            class="badge badge-pill badge-info">VentureBeat</span></a>
                      <a
                         href="https://www.forbes.com/sites/janakirammsv/2024/02/05/how-olmo-from-the-ai2-redefines-llm-innovation/?sh=7927742b6147"><span
                            class="badge badge-pill badge-info">Forbes</span></a>
                      <a
                         href="https://www.geekwire.com/2024/allen-institute-for-ai-promises-new-insights-into-large-language-models-with-olmo-release/"><span
                            class="badge badge-pill badge-info">GeekWire</span></a>
                      <a
                         href="https://www.axios.com/2024/02/01/allen-institute-for-ai-fully-open-source-large-language-model-olmo-7b"><span
                            class="badge badge-pill badge-info">Axios</span></a>
                      <a href="https://sdtimes.com/ai/ai2-releases-olmo-an-open-llm/"><span
                            class="badge badge-pill badge-info">SD Times</span></a>
                      <a
                         href="https://www.fastcompany.com/91021305/ai2-new-open-source-llm?partner=rss&utm_source=rss&utm_medium=feed&utm_campaign=rss+fastcompany&utm_content=rss"><span
                            class="badge badge-pill badge-info">Fast Company</span></a><br /><br />
 
 
 
 
                      <strong>Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining
                         Research</strong><br />
                         🏆 <font color=red><i>ACL Best Resource Paper Award</i> </font> <br />
                      Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin Schwenk, David Atkinson, Russell Authur,
                      Ben Bogin, Khyathi Chandu, Jennifer Dumas, Yanai Elazar, Valentin Hofmann, Ananya Harsh Jha,
                      Sachin Kumar, Li Lucy, Xinxi Lyu, Nathan Lambert, Ian Magnusson,
                      Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters,
                      <u>Abhilasha Ravichander</u>, Kyle Richardson, Zejiang Shen, Emma Strubell, Nishant
                      Subramani, Oyvind Tafjord, Pete Walsh, Luke Zettlemoyer, Noah A. Smith, Hannaneh Hajishirzi,
                      Iz Beltagy, Dirk Groeneveld, Jesse Dodge, Kyle Lo<br />
                      62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)<br />
                      <a href="https://arxiv.org/abs/2402.00159"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/allenai/dolma'><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span> </a> <br />
                      📰 Press: <a
                         href="https://techcrunch.com/2023/08/18/ai2-drops-biggest-open-dataset-yet-for-training-language-models/"><span
                            class="badge badge-pill badge-info">TechCrunch</span></a>
                      <a
                         href="https://www.marktechpost.com/2023/08/23/ai2-unveils-dolma-a-3-trillion-token-corpus-pioneering-transparency-in-language-model-research/"><span
                            class="badge badge-pill badge-info">Marktechpost</span></a>
                      <a
                         href="https://voicebot.ai/2023/08/22/allen-institute-for-ai-releases-largest-open-text-dataset-ever-to-boost-ai-research-transparency/"><span
                            class="badge badge-pill badge-info">Voicebot</span></a>
                      <br /><br />
 
                      <strong>Agent Lumos: Unified and Modular Training for Open-Source Language
                         Agents</strong><br />
                      Da Yin, Faeze Brahman, <u>Abhilasha Ravichander</u>, Khyathi Chandu, Kai-Wei Chang, Yejin
                      Choi, Bill Yuchen Lin<br />
                      62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)<br />
                      <a href="https://arxiv.org/abs/2311.05657"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/allenai/lumos'><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span> </a> <a href="https://allenai.github.io/lumos/"><span
                            class="label-website">Website</span></a> <br />
                      📰 Press: <a
                         href="https://www.marktechpost.com/2024/04/01/lumos-an-open-source-generalizable-language-agent-training-framework/"><span
                            class="badge badge-pill badge-info">Marktechpost</span></a>
 
                      <br /><br />
 
 
 
 
                      <strong>MacGyver: Are Large Language Models Creative Problem Solvers?</strong><br />
                      Yufei Tian, <u>Abhilasha Ravichander</u>, Lianhui Qin, Ronan Le Bras, Raja Marjieh, Nanyun
                      Peng, Yejin Choi, Thomas L
                      Griffiths, Faeze Brahman<br />
                      2024 Annual Conference of the North American Chapter of the Association for Computational
                      Linguistics (NAACL 2024) <br />
                      <a href="https://arxiv.org/abs/2311.09682"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/allenai/MacGyver'><span class='label-code'>Code/Data</span></a> <span
                         class="label-long">Long</span> </a>
                      <br /><br />

                                            
                     <strong>WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries</strong><br />
                      
                     Wenting Zhao, Tanya Goyal, Yu Ying Chiu, Liwei Jiang, Benjamin Newman, <u>Abhilasha Ravichander</u>, Khyathi Chandu, Ronan Le Bras, Claire Cardie, Yuntian Deng, Yejin Choi<br />
                     arXiv<br />
                     <a href="https://arxiv.org/pdf/2407.17468"><span class='label-pdf'>PDF</span></a> <a
                        href='#'><span class='label-code'>Code/Data</span></a>
                     <span class="label-long">Long</span> </a><br /><br />
 
 
 
                      <strong>What’s In My Big Data?</strong> <br />
                      <font color=red><i>Spotlight</i></font><br />
                      Yanai Elazar, Akshita Bhagia, Ian Magnusson, <u>Abhilasha Ravichander</u>, Dustin Schwenk,
                      Alane Suhr, Evan Pete Walsh,
                      Dirk Groeneveld, Luca Soldaini, Sameer Singh, Hannaneh Hajishirzi, Noah A. Smith, Jesse
                      Dodge<br />
                      2024 International Conference on Learning Representations, (ICLR 2024). <br />
                      <a href="https://arxiv.org/abs/2310.20707"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/allenai/wimbd'><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span> </a><a href="https://wimbd.apps.allenai.org/"><span
                            class="label-website">Website</span></a> <br />
                      📰 Press: <a
                         href="https://www.marktechpost.com/2023/11/05/peeking-inside-pandoras-box-unveiling-the-hidden-complexities-of-language-model-datasets-with-whats-in-my-big-data-wimbd/"><span
                            class="badge badge-pill badge-info">Marktechpost</span></a>
                      <br /><br />
 
 
                      <strong>The Generative AI Paradox: “What It Can Create, It May Not
                         Understand”</strong><br />
                      Peter West, Ximing Lu, Nouha Dziri, Faeze Brahman, Linjie Li, Jena D. Hwang, Liwei Jiang,
                      Jillian Fisher, <u>Abhilasha
                         Ravichander</u>, Khyathi Chandu, Benjamin Newman, Pang Wei Koh, Allyson Ettinger, Yejin
                      Choi<br />
                      2024 International Conference on Learning Representations, (ICLR 2024). <br />
                      <a href="https://arxiv.org/abs/2311.00059"><span class='label-pdf'>PDF</span></a> <span
                         class="label-long">Long</span> </a> <br /><br />
 
 
                      <strong>The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context
                         Learning</strong><br />
                      Bill Yuchen Lin, <u>Abhilasha Ravichander</u>, Ximing Lu, Nouha Dziri, Melanie Sclar,
                      Khyathi Chandu, Chandra Bhagavatula,
                      Yejin Choi <br />
                      2024 International Conference on Learning Representations, (ICLR 2024). <br />
                      <a href="https://arxiv.org/abs/2312.01552"><span class='label-pdf'>PDF</span></a> <a
                         href='https://github.com/Re-Align/urial'><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span> </a> <a href="https://allenai.github.io/re-align/"><span
                            class="label-website">Website</span></a><br /><br />
 
                      <strong>Understanding How to Inform Blind and Low-Vision Users about Data Privacy through
                         Privacy Question Answering Assistants</strong><br />
                      Yuanyuan Feng, <u>Abhilasha Ravichander</u>, Yaxing Yao, Shikun Zhang, Rex Chen, Shomir
                      Wilson, Norman Sadeh<br />
                      USENIX Security 2024. <br />
                      <a href="https://arxiv.org/abs/2310.08687"><span class='label-pdf'>PDF</span></a> <span
                         class="label-long">Long</span></br></br>
 
 <!--                      <h3>2023</h3><br /> -->
 
                      <strong>Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without
                         Fine-tuning</strong><br />
                      Ximing Lu, Faeze Brahman, Peter West, Jaehun Jang, Khyathi Chandu, <u>Abhilasha
                         Ravichander</u>, Lianhui Qin, Prithviraj
                      Ammanabrolu, Liwei Jiang, Sahana Ramnath, Nouha Dziri, Jillian Fisher, Bill Yuchen Lin,
                      Skyler Hallinan, Xiang Ren, Sean
                      Welleck, Yejin Choi <br />
                      2023 Conference on Empirical Methods in Natural Language Processing, (EMNLP 2023). <br />
                      <a href="https://arxiv.org/abs/2305.15065"><span class='label-pdf'>PDF</span></a> <a
                         href="https://github.com/GXimingLu/IPA"><span class='label-code'>Code/Data</span></a>
                      <span class="label-long">Long</span>
                      <!-- <span class="label-slides">Slides</span> --><br /><br />
 
 
 
 
             <strong>When and Why Does Bias Mitigation Work?</strong><br />
             <u>Abhilasha Ravichander</u>*, Joe Stacey*, Marek Rei <br />
             Findings of the 2023 Conference on Empirical Methods in Natural Language Processing,
             (EMNLP Findings 2023). <br />
             <a href="https://arxiv.org/abs/2211.00295"><span class='label-pdf'>PDF</span></a> <a
                href='https://github.com/AbhilashaRavichander/CondaQA'><span class='label-code'>Code/Data</span></a>
             <span class="label-long">Long</span>
             <!-- <span class="label-slides">Slides</span> --><br /><br />
        
 
 <!--             <h3>2022</h3><br /> -->
             <strong>CondaQA: A Contrastive Reading Comprehension Dataset for Reasoning about
                Negation</strong> <br />
                🏆 <font color=red><i>SoCal NLP Symposium best paper award</i> </font> <br />
             <u>Abhilasha Ravichander</u>, Matt Gardner, Ana Marasović <br />
             2022 Conference on Empirical Methods in Natural Language Processing, (EMNLP 2022).<br />
             <a href="https://aclanthology.org/2023.findings-emnlp.619/"><span class='label-pdf'>PDF</span></a> <span
                class='label-code'>Code/Data</span> <span class="label-long">Long</span>
             <!-- <span class="label-slides">Slides</span> --><br /><br />
 
             <strong>Measuring Causal Effects of Data Statistics on Language Model's `Factual'
                Predictions</strong><br />
             Yanai Elazar, Nora Kassner, Shauli Ravfogel, Amir Feder, <u>Abhilasha Ravichander</u>,
             Marius Mosbach, Yonatan Belinkov, Hinrich Schütze, Yoav Goldberg <br />
             arXiv.<br />
             <a href="https://arxiv.org/abs/2207.14251"><span class='label-pdf'>PDF</span></a>
             <br /><br />
 
 
             <strong>A Tale of Two Regulatory Regimes: Creation and Analysis of a Bilingual Privacy
                Policy Corpus</strong><br />
             Siddhant Arora, Henry Hosseini, Christine Utz, Vinayshekhar Bannihatti Kumar, Tristan
             Dhellemmes, <u>Abhilasha Ravichander</u>, Peter Story, Jasmine Mangat, Rex Chen, Martin
             Degeling, Thomas Norton, Thomas Hupperich, Shomir Wilson, Norman Sadeh <br />
             Thirteenth Language Resources and Evaluation Conference, (LREC 2022).<br />
             <a href="https://aclanthology.org/2022.lrec-1.585/"><span class='label-pdf'>PDF</span></a>
             <a href='https://usableprivacy.org/data'><span class='label-code'>Code/Data</span></a>
             <span class="label-long">Long</span>
             <!-- <span class="label-slides">Slides</span> --></br></br>
 
 
 <!--             <h3>2021</h3><br /> -->
 
 
                   <strong>Probing the Probing Paradigm: Does Probing Accuracy Entail Task
                      Relevance?</strong><br />
                   <u>Abhilasha Ravichander</u>, Yonatan Belinkov, Eduard Hovy <br />
                   16th Conference of the European Chapter of the Association for Computational Linguistics,
                   (EACL 2021).<br />
                   <a href="https://arxiv.org/abs/2005.00719"><span class='label-pdf'>PDF</span></a> <a href='#'><span
                         class='label-code'>Code/Data</span></a> <span class="label-long">Long</span>
                   <!-- <span class="label-slides">Slides</span> --><br /><br />
 
                   <strong>NoiseQA: Challenge Set Evaluation for User-Centric Question
                      Answering</strong><br />
                   <u>Abhilasha Ravichander</u>, Siddharth Dalmia, Maria Ryskina, Florian Metze, Eduard Hovy,
                   Alan W Black <br />
                   16th Conference of the European Chapter of the Association for Computational Linguistics,
                   (EACL 2021).<br />
                   <a href="https://arxiv.org/abs/2102.08345"><span class='label-pdf'>PDF</span></a> <a
                      href='https://github.com/noiseQA/NoiseQA'><span class='label-code'>Code/Data</span></a>
                   <span class="label-long">Long</span> <a href='https://noiseqa.github.io/'><span
                         class="label-website">Website</span></a>
                   <!-- <span class="label-slides">Slides</span> --><br /><br />
 
                   <strong>Measuring and Improving Consistency in Pretrained Language Models</strong><br />
                   Yanai Elazar, Nora Kassner, Shauli Ravfogel, <u>Abhilasha Ravichander</u>, Eduard Hovy,
                   Hinrich Schütze, Yoav Goldberg <br />
                   Transactions of the Association of Computational Linguistics, (TACL 2021).<br />
                   <a href="https://arxiv.org/abs/2102.01017"><span class='label-pdf'>PDF</span></a> <a
                      href='https://github.com/yanaiela/pararel'><span class='label-code'>Code/Data</span></a> <span
                      class="label-long">Long</span>
                   <br /><br />
 
                   <strong>Breaking Down Walls of Text: How Can NLP Benefit Consumer Privacy?</strong><br />
                   <u>Abhilasha Ravichander</u>, Alan W Black, Thomas Norton, Shomir Wilson and Norman
                   Sadeh.<br />
                   59th Annual Meeting of the Association for Computational Linguistics, (ACL 2021) <br />
                   <a href=""><span class='label-pdf'>PDF</span></a> <span class="label-long">Long</span><br /><br />
                <!-- </br></br><hr></br> -->
 
 <!--             <h3>2020</h3><br />   -->
                   <strong>On the Systematicity of Probing Contextualized Word Representations: The Case of
                      Hypernymy in BERT</strong><br />
                   <u>Abhilasha Ravichander</u>, Eduard Hovy, Kaheer Suleman, Adam Trischler, Jackie Chi Kit
                   Cheung. <br />
                   2020 Joint Conference on Lexical and Computational Semantics, (*SEM 2020). <br />
                   <a href="https://www.aclweb.org/anthology/2020.starsem-1.10/"><span class='label-pdf'>PDF</span></a>
                   <a href='https://github.com/AbhilashaRavichander/probe-generalization'><span
                         class='label-code'>Code/Data</span></a> <span class="label-long">Long</span>
                        </br></br> 
 <!--             <h3>2019</h3><br />   -->
                   <strong>EQUATE: A Benchmark Evaluation Framework for Quantitative Reasoning in Natural
                      Language Inference</strong><br />
                   <u>Abhilasha Ravichander*</u>, Aakanksha Naik*, Carolyn Rose, Eduard Hovy <br />
                   2019 Conference on Computational Natural Language Learning, (CoNLL 2019).<br />
                   <a href="https://arxiv.org/abs/1901.03735"><span class='label-pdf'>PDF</span></a> <a
                      href='https://github.com/AbhilashaRavichander/EQUATE'><span class='label-code'>Code/Data</span></a>
                   <span class="label-long">Long</span><br /><br />
 
                   <strong>Question Answering for Privacy Policies: Combining Computational and Legal
                      Perspectives</strong><br />
                   <u>Abhilasha Ravichander</u>, Alan W Black, Shomir Wilson, Thomas Norton and Norman
                   Sadeh.<br />
                   2019 Conference on Empirical Methods in Natural Language Processing, (EMNLP 2019) <br />
                   <a href="https://www.aclweb.org/anthology/D19-1500/"><span class='label-pdf'>PDF</span></a> <a
                      href='https://github.com/AbhilashaRavichander/PrivacyQA/'><span
                         class='label-code'>Code/Data</span></a> <span class="label-long">Long</span>
                   <br /><br />
 
                   <strong>Exploring Numeracy in Word Embeddings</strong><br />Aakanksha Naik*, <u>Abhilasha
                      Ravichander*</u>, Carolyn Rose, Eduard Hovy <br />
                   57th Meeting of Association for Computational Linguistics, (ACL
                   2019).&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br />
                   <a href="https://arxiv.org/abs/1806.00692"><span class='label-pdf'>PDF</span></a> <span
                      class="label-short">Short</span> <br /><br />
 
                   <strong>Evaluating How Global Privacy Principles Answer Consumers’ Questions About Mobile
                      App Privacy.</strong><br />
                   Thomas Norton, Joel Reidenberg, Norman Sadeh and <u>Abhilasha Ravichander</u><br />
                   4th European Privacy Law Scholars Conference, (PLSC 2019).<br /><br />
 
                   <strong>Challenges in Automated Question Answering for Privacy Policies.</strong><br />
                   <u>Abhilasha Ravichander</u>, Alan Black, Eduard Hovy, Joel Reidenberg, N. Cameron Russell
                   and Norman Sadeh<br />
                   AAAI Spring Symposium Series, 2019<br />
                   <a href="http://ceur-ws.org/Vol-2335/1st_PAL_paper_13.pdf"><span class='label-pdf'>PDF</span></a>
                   <span class="label-long">Long</span> <br /><br />
 
                   <strong>MAPS: Scaling Privacy Compliance Analysis to a Million Apps</strong><br />
                   Peter Story, Sebastian Zimmeck, Daniel Smullen, <u>Abhilasha Ravichander</u>, Ziqi Wang,
                   Joel Reidenberg, N. Cameron Russell and Norman Sadeh <br />
                   PETS 2019 <br />
                   <a href="https://content.sciendo.com/view/journals/popets/2019/3/article-p66.xml?tab_body=pdf"><span
                         class='label-pdf'>PDF</span></a> <span class="label-long">Long</span> 

                        </br></br>
 <!--          <h3>2018</h3><br /> -->
                   <strong>Stress Test Evaluation for Natural Language Inference</strong> <br /> <font color=red>
                    🏆   <i>Area Chair Favorite Paper Prize</i> </font> <br />
                   Aakanksha Naik*, <u>Abhilasha Ravichander*</u>, Norman Sadeh, Carolyn Rose, Graham Neubig.
                   <br />
                   <i>27th International Conference on Computational Linguistics</i>, (COLING 2018). <br />
                   <a href="https://arxiv.org/abs/1806.00692"><span class='label-pdf'>PDF</span></a> <a
                      href='https://abhilasharavichander.github.io/NLI_StressTest/'><span
                         class='label-code'>Code/Data</span></a> <span class="label-long">Long</span> <a
                      href='https://abhilasharavichander.github.io/NLI_StressTest/'> <span
                         class="label-website">Website</span></a> <a
                      href='https://github.com/AbhilashaRavichander/NLI_StressTest/blob/master/slides.pdf'><span
                         class="label-slides">Slides</span></a><br /><br />
 
             <!-- <div class="row">
                            <div class="col-sm-1">
                               2018
                            </div>
                            <div class="col-sm-11">
                               <strong>An Empirical Study of Self-Disclosure in Spoken Dialogue Systems</strong><br />
                               <u>Abhilasha Ravichander</u>, Alan Black. <br />
                               <i>19th Annual SIGdial Meeting on Discourse and Dialogue</i>, (SIGDIAL 2018). <br />
                               <a href="http://aclweb.org/anthology/W18-5030"><span class='label-pdf'>PDF</span></a><span class="label-long">Long</span> <br /><br />
                            </div>
                         </div> -->
 
                   <strong>An Empirical Study of Self-Disclosure in Spoken Dialogue Systems</strong><br />
                   <u>Abhilasha Ravichander</u>, Alan Black. <br />
                   <i>19th Annual SIGdial Meeting on Discourse and Dialogue</i>, (SIGDIAL
                   2018).&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                   <br />
                   <a href="http://aclweb.org/anthology/W18-5030"><span class='label-pdf'>PDF</span></a><span
                      class="label-long">Long</span> 
                   <br /><br />

 <!--                   <h3>2017</h3><br />                -->
                   <strong>Does the Geometry of Word Embeddings Help Document Classification? A Case Study on
                      Persistent Homology-Based Representations</strong><br />
                   Paul Michel*, <u>Abhilasha Ravichander*</u>, Shruti Rijhwani*.<br />
                   <i>Workshop on Representation Learning For NLP</i>, Association for Computational
                   Linguistics, 2017 (ACL 2017). <br />
                   <a href="http://www.aclweb.org/anthology/W17-2628"><span class='label-pdf'>PDF</span></a>
                   <span class="label-short">Short</span><br /><br />
 
                   <strong>How Would You Say It? Eliciting Lexically Diverse Data for Supervised Semantic
                      Parsing</strong><br />
                   <u>Abhilasha Ravichander*</u>, Thomas Manzini*, Matthias Grabmair, Jonathan Francis,
                   Graham Neubig, Eric Nyberg. <br />
                   <i>18th Annual SIGdial Meeting on Discourse and Dialogue</i>, (SIGDIAL 2017).<br /> <a
                      href="http://aclweb.org/anthology/W17-5545"><span class='label-pdf'>PDF</span></a> <a
                      href='https://github.com/oaqa/resources'><span class='label-code'>Code/Data</span></a>
                   <span class="label-long">Long</span> <br /><br />
 
          </div>
        </div>
 



  </main>

  <footer>
    Last updated May 2025. 
  </footer>
</body>
</html>
